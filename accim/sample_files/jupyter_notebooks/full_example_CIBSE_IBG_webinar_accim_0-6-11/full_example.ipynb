{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3991fa3e",
   "metadata": {},
   "source": [
    "# Full example: energy demand using adaptive setpoint temperatures in Japan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e978db",
   "metadata": {},
   "source": [
    "In this notebook, we're going to run a simulation with adaptive setpoint temperatures based on ASHRAE 55, and we are going to compare these with the static setpoints from the COOLBIZ campaign. Also, we are going to run simulations considering the ASHRAE 55 in NV mode, to compare it with MM. We are going to run some simulations  in Sapporo and Naha (some Japanese locations), and also we are going to analyse and visualize the data. This Jupyter Notebook partially replicates the research paper _Extending the use of adaptive thermal comfort to air-conditioning: the case study of a local Japanese comfort model in present and future scenarios_[1].\n",
    "\n",
    "[1] Sánchez-García, D., Bienvenido-Huertas, D., Pulido-Arcas, J.A., Rubio-Bellido, C., 2023. Extending the use of adaptive thermal comfort to air-conditioning: The case study of a local Japanese comfort model in present and future scenarios. Energy Build. 285, 112901. https://doi.org/10.1016/j.enbuild.2023.112901\n",
    "\n",
    "First of all, given EnergyPlus 23.1 is installed in the default path (C:\\EnergyPlusV23-1-0), and accim 0.6.11 has been installed by entering 'pip install accim==0.6.11' in the CMD dialog, let's prepare the files we need: the IDF(s) and the EPW(s). Let's see what file we have in the folder and then we'll continue with the IDF(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72f26c4",
   "metadata": {},
   "source": [
    "First of all, let's store the input files names so that we can re-run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd6f4d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "input_files = [i for i in listdir()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b71ab",
   "metadata": {},
   "source": [
    "## 1. IDF (using `addAccis()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a5c34",
   "metadata": {},
   "source": [
    "Say we have one or multiple IDF files, with an existing HVAC system (in this case, the use of mixed-mode ScriptType 'ex_mm' is not recommended; only full air-conditioning) or with no HVAC system at all (in this case, any of the 'vrf_ac' or 'vrf_mm' ScriptTypes are recommended). In this example, we are going to use an IDF without HVAC system, and we are going to use 'vrf_mm' so that accim adds a generic VRF system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2939dcd3",
   "metadata": {},
   "source": [
    "Let's see what IDFs we do have in our folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55bd779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TestModel.idf']\n"
     ]
    }
   ],
   "source": [
    "input_idfs = [i for i in listdir() if i.endswith('.idf')]\n",
    "print(input_idfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ac1b0",
   "metadata": {},
   "source": [
    "So now, we're going to generate building energy models with setpoint temperatures based on the static setpoints for Japan (i.e. ComfStand takes the value 3) and ASHRAE 55 (i.e. ComfStand takes the value 2). We're going to select the 80% acceptability levels for both (i.e. CAT takes the value 80), and we're going to select the setpoint behaviour to horizontally extend the setpoint temperatures (or comfort limits) when applicability limits are exceeded (i.e. ComfMod takes the value 3). There are 2 methods to apply adaptive setpoint temperatures:\n",
    "- Short method, which is running the following to lines of code:\n",
    "```\n",
    "from accim.sim import accis\n",
    "accis.addAccis()\n",
    "```\n",
    "\n",
    "When we run the 2 lines of code above, accim is going to ask us to enter some information it needs to generate the output IDFs. The data we're going to input, in the same order, is:\n",
    "- Enter the ScriptType: **vrf_mm**\n",
    "- Enter the SupplyAirTempInputMethod: **temperature difference**\n",
    "- Do you want to keep the existing outputs (true or false)?: **false**\n",
    "- Enter the Output type (standard, simplified or detailed): **standard**\n",
    "- Enter the Output frequencies separated by space (timestep, hourly, daily, monthly, runperiod): **hourly**\n",
    "- Enter the EnergyPlus version (9.1 to 23.1): **23.1**\n",
    "- Enter the Temperature Control method (temperature or pmv): **temperature**\n",
    "\n",
    "After that, accim will let us know the information we have entered, and it will start the generic IDF generation process. Lots of actions are going to be performed, and all of them will be printed on screen. Once this process is done, accim will let us know if any of the IDFs is not going to work for any reason, and then it will start the output IDF files generation process. Then, accim will ask us again to enter some information, this time to generate the output IDF(s). The data we are going to enter now is:\n",
    "\n",
    "- Enter the Comfort Standard numbers separated by space: **2 3**\n",
    "- Enter the Category numbers separated by space: **80**\n",
    "- Enter the Comfort Mode numbers separated by space: **0 3** (where 0 and 3 are respectively static and adaptive setpoints)\n",
    "- Enter the HVAC Mode numbers separated by space: **1 2** (in this case we have also selected 1 for naturally ventilated, to see the difference with mixed-mode)\n",
    "- Enter the Ventilation Control numbers separated by space: **0**\n",
    "\n",
    "For all the remaining arguments, we're going to hit enter to omit it and take the default value. Finally, accim will let us know the list of output IDFs and will ask for confirmation to proceed:\n",
    "\n",
    "- Do you still want to run ACCIS? [y/n]: **y**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372843fa",
   "metadata": {},
   "source": [
    "Alternatively, we could specify all the arguments when calling the function, as shown in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd4b7ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------\n",
      "Adaptive-Comfort-Control-Implemented Model (ACCIM)\n",
      "--------------------------------------------------------\n",
      "\n",
      "This tool allows to apply adaptive setpoint temperatures. \n",
      "For further information, please read the documentation: \n",
      "https://accim.readthedocs.io/en/master/\n",
      "For a visual understanding of the tool, please visit the following jupyter notebooks:\n",
      "-    Using addAccis() to apply adaptive setpoint temperatures\n",
      "https://github.com/dsanchez-garcia/accim/blob/master/accim/sample_files/jupyter_notebooks/addAccis/using_addAccis.ipynb\n",
      "-    Using rename_epw_files() to rename the EPWs for proper data analysis after simulation\n",
      "https://github.com/dsanchez-garcia/accim/blob/master/accim/sample_files/jupyter_notebooks/rename_epw_files/using_rename_epw_files.ipynb\n",
      "-    Using runEp() to directly run simulations with EnergyPlus\n",
      "https://github.com/dsanchez-garcia/accim/blob/master/accim/sample_files/jupyter_notebooks/runEp/using_runEp.ipynb\n",
      "-    Using the class Table() for data analysis\n",
      "https://github.com/dsanchez-garcia/accim/blob/master/accim/sample_files/jupyter_notebooks/Table/using_Table.ipynb\n",
      "\n",
      "Starting with the process.\n",
      "Basic input data:\n",
      "ScriptType is: vrf_mm\n",
      "Supply Air Temperature Input Method is: temperature difference\n",
      "Output type is: standard\n",
      "Output frequencies are: \n",
      "['hourly']\n",
      "EnergyPlus version is: 23.1\n",
      "Temperature Control method is: temperature\n",
      "\n",
      "=======================START OF GENERIC IDF FILE GENERATION PROCESS=======================\n",
      "\n",
      "Starting with file:\n",
      "TestModel\n",
      "IDD location is: C:\\EnergyPlusV23-1-0\\Energy+.idd\n",
      "The occupied zones in the model TestModel are:\n",
      "BLOCK1:ZONE2\n",
      "BLOCK1:ZONE1\n",
      "The windows and doors in the model TestModel are:\n",
      "Block1_Zone2_Wall_3_0_0_0_0_0_Win\n",
      "Block1_Zone2_Wall_4_0_0_0_0_0_Win\n",
      "Block1_Zone2_Wall_5_0_0_0_0_0_Win\n",
      "Block1_Zone1_Wall_2_0_0_0_0_0_Win\n",
      "Block1_Zone1_Wall_3_0_0_0_0_0_Win\n",
      "Block1_Zone1_Wall_5_0_0_0_0_0_Win\n",
      "The zones in the model TestModel are:\n",
      "BLOCK1_ZONE2\n",
      "BLOCK1_ZONE1\n",
      "The people objects in the model have been amended.\n",
      "BLOCK1:ZONE2 Thermostat has been added\n",
      "BLOCK1:ZONE1 Thermostat has been added\n",
      "On Schedule already was in the model\n",
      "TypOperativeTempControlSch Schedule already was in the model\n",
      "All ZoneHVAC:IdealLoadsAirSystem Heating and Cooling availability schedules has been set to on\n",
      "On 24/7 Schedule already was in the model\n",
      "Control type schedule: Always 4 Schedule has been added\n",
      "Relative humidity setpoint schedule: Always 50.00 Schedule has been added\n",
      "Heating Fanger comfort setpoint: Always -0.5 Schedule has been added\n",
      "Cooling Fanger comfort setpoint: Always  0.1 Schedule has been added\n",
      "Zone CO2 setpoint: Always 900ppm Schedule has been added\n",
      "Min CO2 concentration: Always 600ppm Schedule has been added\n",
      "Generic contaminant setpoint: Always 0.5ppm Schedule has been added\n",
      "Air distribution effectiveness (always 1) Schedule has been added\n",
      "VRF Heating Cooling (Northern Hemisphere) Schedule has been added\n",
      "DefaultFanEffRatioCurve Curve:Cubic Object has been added\n",
      "VRFTUCoolCapFT Curve:Cubic Object has been added\n",
      "VRFTUHeatCapFT Curve:Cubic Object has been added\n",
      "VRFCoolCapFTBoundary Curve:Cubic Object has been added\n",
      "VRFCoolEIRFTBoundary Curve:Cubic Object has been added\n",
      "CoolingEIRLowPLR Curve:Cubic Object has been added\n",
      "VRFHeatCapFTBoundary Curve:Cubic Object has been added\n",
      "VRFHeatEIRFTBoundary Curve:Cubic Object has been added\n",
      "HeatingEIRLowPLR Curve:Cubic Object has been added\n",
      "DefaultFanPowerRatioCurve Curve:Exponent Object has been added\n",
      "DXHtgCoilDefrostEIRFT Curve:Biquadratic Object has been added\n",
      "VRFCoolCapFT Curve:Biquadratic Object has been added\n",
      "VRFCoolCapFTHi Curve:Biquadratic Object has been added\n",
      "VRFCoolEIRFT Curve:Biquadratic Object has been added\n",
      "VRFCoolEIRFTHi Curve:Biquadratic Object has been added\n",
      "VRFHeatCapFT Curve:Biquadratic Object has been added\n",
      "VRFHeatCapFTHi Curve:Biquadratic Object has been added\n",
      "VRFHeatEIRFT Curve:Biquadratic Object has been added\n",
      "VRFHeatEIRFTHi Curve:Biquadratic Object has been added\n",
      "CoolingLengthCorrectionFactor Curve:Biquadratic Object has been added\n",
      "VRF Piping Correction Factor for Length in Heating Mode Curve:Biquadratic Object has been added\n",
      "VRF Heat Recovery Cooling Capacity Modifier Curve:Biquadratic Object has been added\n",
      "VRF Heat Recovery Cooling Energy Modifier Curve:Biquadratic Object has been added\n",
      "VRF Heat Recovery Heating Capacity Modifier Curve:Biquadratic Object has been added\n",
      "VRF Heat Recovery Heating Energy Modifier Curve:Biquadratic Object has been added\n",
      "VRFACCoolCapFFF Curve:Quadratic Object has been added\n",
      "CoolingEIRHiPLR Curve:Quadratic Object has been added\n",
      "VRFCPLFFPLR Curve:Quadratic Object has been added\n",
      "HeatingEIRHiPLR Curve:Quadratic Object has been added\n",
      "CoolingCombRatio Curve:Linear Object has been added\n",
      "HeatingCombRatio Curve:Linear Object has been added\n",
      "VRF Outdoor Unit_BLOCK1:ZONE2 AirConditioner:VariableRefrigerantFlow Object has been added\n",
      "VRF Outdoor Unit_BLOCK1:ZONE1 AirConditioner:VariableRefrigerantFlow Object has been added\n",
      "VRF Outdoor Unit_BLOCK1:ZONE2 Outdoor Air Node Object has been added\n",
      "VRF Outdoor Unit_BLOCK1:ZONE2 Zone List Object has been added\n",
      "VRF Outdoor Unit_BLOCK1:ZONE1 Outdoor Air Node Object has been added\n",
      "VRF Outdoor Unit_BLOCK1:ZONE1 Zone List Object has been added\n",
      "BLOCK1:ZONE2 Sizing:Zone Object has been added\n",
      "BLOCK1:ZONE1 Sizing:Zone Object has been added\n",
      "BLOCK1:ZONE2 Design Specification Outdoor Air Object has been added\n",
      "BLOCK1:ZONE1 Design Specification Outdoor Air Object has been added\n",
      "BLOCK1:ZONE2 Design Specification Zone Air Distribution Object has been added\n",
      "BLOCK1:ZONE1 Design Specification Zone Air Distribution Object has been added\n",
      "BLOCK1:ZONE2 Nodelist Objects has been added\n",
      "BLOCK1:ZONE1 Nodelist Objects has been added\n",
      "BLOCK1:ZONE2 ZoneHVAC:EquipmentConnections Objects has been added\n",
      "BLOCK1:ZONE1 ZoneHVAC:EquipmentConnections Objects has been added\n",
      "BLOCK1:ZONE2 ZoneHVAC:EquipmentList Objects has been added\n",
      "BLOCK1:ZONE1 ZoneHVAC:EquipmentList Objects has been added\n",
      "BLOCK1:ZONE2 ZoneHVAC:TerminalUnit:VariableRefrigerantFlow Object has been added\n",
      "BLOCK1:ZONE1 ZoneHVAC:TerminalUnit:VariableRefrigerantFlow Object has been added\n",
      "BLOCK1:ZONE2 Coil:Cooling:DX:VariableRefrigerantFlow Object has been added\n",
      "BLOCK1:ZONE1 Coil:Cooling:DX:VariableRefrigerantFlow Object has been added\n",
      "BLOCK1:ZONE2 Coil:Heating:DX:VariableRefrigerantFlow Object has been added\n",
      "BLOCK1:ZONE1 Coil:Heating:DX:VariableRefrigerantFlow Object has been added\n",
      "BLOCK1:ZONE2 Fan:ConstantVolume Object has been added\n",
      "BLOCK1:ZONE1 Fan:ConstantVolume Object has been added\n",
      "Vent_SP_temp Schedule has been added\n",
      "AHST_Sch_BLOCK1_ZONE2 Schedule has been added\n",
      "ACST_Sch_BLOCK1_ZONE2 Schedule has been added\n",
      "AHST_Sch_BLOCK1_ZONE1 Schedule has been added\n",
      "ACST_Sch_BLOCK1_ZONE1 Schedule has been added\n",
      "Added - SetComfTemp Program\n",
      "Added - CountHours_BLOCK1_ZONE2 Program\n",
      "Added - CountHours_BLOCK1_ZONE1 Program\n",
      "Added - SetAppLimits Program\n",
      "Added - ApplyCAT Program\n",
      "Added - SetAST Program\n",
      "Added - SetASTnoTol Program\n",
      "Added - CountHoursNoApp_BLOCK1_ZONE2 Program\n",
      "Added - SetGeoVarBLOCK1_ZONE2 Program\n",
      "Added - CountHoursNoApp_BLOCK1_ZONE1 Program\n",
      "Added - SetGeoVarBLOCK1_ZONE1 Program\n",
      "Added - SetInputData Program\n",
      "Added - SetVOFinputData Program\n",
      "Added - SetVST Program\n",
      "Added - ApplyAST_BLOCK1_ZONE2 Program\n",
      "Added - ApplyAST_BLOCK1_ZONE1 Program\n",
      "Added - SetMyVOF_Block1_Zone2_Wall_3_0_0_0_0_0_Win Program\n",
      "Added - SetWindowOperation_Block1_Zone2_Wall_3_0_0_0_0_0_Win Program\n",
      "Added - SetMyVOF_Block1_Zone2_Wall_4_0_0_0_0_0_Win Program\n",
      "Added - SetWindowOperation_Block1_Zone2_Wall_4_0_0_0_0_0_Win Program\n",
      "Added - SetMyVOF_Block1_Zone2_Wall_5_0_0_0_0_0_Win Program\n",
      "Added - SetWindowOperation_Block1_Zone2_Wall_5_0_0_0_0_0_Win Program\n",
      "Added - SetMyVOF_Block1_Zone1_Wall_2_0_0_0_0_0_Win Program\n",
      "Added - SetWindowOperation_Block1_Zone1_Wall_2_0_0_0_0_0_Win Program\n",
      "Added - SetMyVOF_Block1_Zone1_Wall_3_0_0_0_0_0_Win Program\n",
      "Added - SetWindowOperation_Block1_Zone1_Wall_3_0_0_0_0_0_Win Program\n",
      "Added - SetMyVOF_Block1_Zone1_Wall_5_0_0_0_0_0_Win Program\n",
      "Added - SetWindowOperation_Block1_Zone1_Wall_5_0_0_0_0_0_Win Program\n",
      "Added - Comfort Temperature Output Variable\n",
      "Added - Adaptive Cooling Setpoint Temperature Output Variable\n",
      "Added - Adaptive Heating Setpoint Temperature Output Variable\n",
      "Added - Adaptive Cooling Setpoint Temperature_No Tolerance Output Variable\n",
      "Added - Adaptive Heating Setpoint Temperature_No Tolerance Output Variable\n",
      "Added - Ventilation Setpoint Temperature Output Variable\n",
      "Added - Minimum Outdoor Temperature for ventilation Output Variable\n",
      "Added - Minimum Outdoor Temperature Difference for ventilation Output Variable\n",
      "Added - Maximum Outdoor Temperature Difference for ventilation Output Variable\n",
      "Added - Multiplier for Ventilation Opening Factor Output Variable\n",
      "Added - Comfortable Hours_No Applicability_BLOCK1_ZONE2 Output Variable\n",
      "Added - Comfortable Hours_No Applicability_BLOCK1_ZONE1 Output Variable\n",
      "Added - Comfortable Hours_Applicability_BLOCK1_ZONE2 Output Variable\n",
      "Added - Comfortable Hours_Applicability_BLOCK1_ZONE1 Output Variable\n",
      "Added - Discomfortable Applicable Hot Hours_BLOCK1_ZONE2 Output Variable\n",
      "Added - Discomfortable Applicable Hot Hours_BLOCK1_ZONE1 Output Variable\n",
      "Added - Discomfortable Applicable Cold Hours_BLOCK1_ZONE2 Output Variable\n",
      "Added - Discomfortable Applicable Cold Hours_BLOCK1_ZONE1 Output Variable\n",
      "Added - Discomfortable Non Applicable Hot Hours_BLOCK1_ZONE2 Output Variable\n",
      "Added - Discomfortable Non Applicable Hot Hours_BLOCK1_ZONE1 Output Variable\n",
      "Added - Discomfortable Non Applicable Cold Hours_BLOCK1_ZONE2 Output Variable\n",
      "Added - Discomfortable Non Applicable Cold Hours_BLOCK1_ZONE1 Output Variable\n",
      "Added - Zone Floor Area_BLOCK1_ZONE2 Output Variable\n",
      "Added - Zone Floor Area_BLOCK1_ZONE1 Output Variable\n",
      "Added - Zone Air Volume_BLOCK1_ZONE2 Output Variable\n",
      "Added - Zone Air Volume_BLOCK1_ZONE1 Output Variable\n",
      "Added - Ventilation Hours_BLOCK1_ZONE2 Output Variable\n",
      "Added - Ventilation Hours_BLOCK1_ZONE1 Output Variable\n",
      "Global variables objects have been added\n",
      "Internal variables objects have been added\n",
      "Added - RMOT Sensor\n",
      "Added - PMOT Sensor\n",
      "Added - BLOCK1_ZONE2_OpT Sensor\n",
      "Added - BLOCK1_ZONE2_WindSpeed Sensor\n",
      "Added - BLOCK1_ZONE2_OutT Sensor\n",
      "Added - BLOCK1_ZONE1_OpT Sensor\n",
      "Added - BLOCK1_ZONE1_WindSpeed Sensor\n",
      "Added - BLOCK1_ZONE1_OutT Sensor\n",
      "Added - Block1_Zone2_Wall_3_0_0_0_0_0_Win_OpT Sensor\n",
      "Added - Block1_Zone2_Wall_3_0_0_0_0_0_Win_WindSpeed Sensor\n",
      "Added - Block1_Zone2_Wall_3_0_0_0_0_0_Win_OutT Sensor\n",
      "Added - Block1_Zone2_Wall_4_0_0_0_0_0_Win_OpT Sensor\n",
      "Added - Block1_Zone2_Wall_4_0_0_0_0_0_Win_WindSpeed Sensor\n",
      "Added - Block1_Zone2_Wall_4_0_0_0_0_0_Win_OutT Sensor\n",
      "Added - Block1_Zone2_Wall_5_0_0_0_0_0_Win_OpT Sensor\n",
      "Added - Block1_Zone2_Wall_5_0_0_0_0_0_Win_WindSpeed Sensor\n",
      "Added - Block1_Zone2_Wall_5_0_0_0_0_0_Win_OutT Sensor\n",
      "Added - Block1_Zone1_Wall_2_0_0_0_0_0_Win_OpT Sensor\n",
      "Added - Block1_Zone1_Wall_2_0_0_0_0_0_Win_WindSpeed Sensor\n",
      "Added - Block1_Zone1_Wall_2_0_0_0_0_0_Win_OutT Sensor\n",
      "Added - Block1_Zone1_Wall_3_0_0_0_0_0_Win_OpT Sensor\n",
      "Added - Block1_Zone1_Wall_3_0_0_0_0_0_Win_WindSpeed Sensor\n",
      "Added - Block1_Zone1_Wall_3_0_0_0_0_0_Win_OutT Sensor\n",
      "Added - Block1_Zone1_Wall_5_0_0_0_0_0_Win_OpT Sensor\n",
      "Added - Block1_Zone1_Wall_5_0_0_0_0_0_Win_WindSpeed Sensor\n",
      "Added - Block1_Zone1_Wall_5_0_0_0_0_0_Win_OutT Sensor\n",
      "Added - OutT Sensor\n",
      "Added - AHST_Act_BLOCK1_ZONE2 Actuator\n",
      "Added - ACST_Act_BLOCK1_ZONE2 Actuator\n",
      "Added - AHST_Act_BLOCK1_ZONE1 Actuator\n",
      "Added - ACST_Act_BLOCK1_ZONE1 Actuator\n",
      "Added - Block1_Zone2_Wall_3_0_0_0_0_0_Win_VentOpenFact Actuator\n",
      "Added - Block1_Zone2_Wall_4_0_0_0_0_0_Win_VentOpenFact Actuator\n",
      "Added - Block1_Zone2_Wall_5_0_0_0_0_0_Win_VentOpenFact Actuator\n",
      "Added - Block1_Zone1_Wall_2_0_0_0_0_0_Win_VentOpenFact Actuator\n",
      "Added - Block1_Zone1_Wall_3_0_0_0_0_0_Win_VentOpenFact Actuator\n",
      "Added - Block1_Zone1_Wall_5_0_0_0_0_0_Win_VentOpenFact Actuator\n",
      "Added - BLOCK1_ZONE2_CoolCoil Sensor\n",
      "Added - BLOCK1_ZONE2_HeatCoil Sensor\n",
      "Added - BLOCK1_ZONE1_CoolCoil Sensor\n",
      "Added - BLOCK1_ZONE1_HeatCoil Sensor\n",
      "Added - Block1_Zone2_Wall_3_0_0_0_0_0_Win_CoolCoil Sensor\n",
      "Added - Block1_Zone2_Wall_3_0_0_0_0_0_Win_HeatCoil Sensor\n",
      "Added - Block1_Zone2_Wall_4_0_0_0_0_0_Win_CoolCoil Sensor\n",
      "Added - Block1_Zone2_Wall_4_0_0_0_0_0_Win_HeatCoil Sensor\n",
      "Added - Block1_Zone2_Wall_5_0_0_0_0_0_Win_CoolCoil Sensor\n",
      "Added - Block1_Zone2_Wall_5_0_0_0_0_0_Win_HeatCoil Sensor\n",
      "Added - Block1_Zone1_Wall_2_0_0_0_0_0_Win_CoolCoil Sensor\n",
      "Added - Block1_Zone1_Wall_2_0_0_0_0_0_Win_HeatCoil Sensor\n",
      "Added - Block1_Zone1_Wall_3_0_0_0_0_0_Win_CoolCoil Sensor\n",
      "Added - Block1_Zone1_Wall_3_0_0_0_0_0_Win_HeatCoil Sensor\n",
      "Added - Block1_Zone1_Wall_5_0_0_0_0_0_Win_CoolCoil Sensor\n",
      "Added - Block1_Zone1_Wall_5_0_0_0_0_0_Win_HeatCoil Sensor\n",
      "Added - SetComfTemp Program Calling Manager\n",
      "Added - CountHours_BLOCK1_ZONE2 Program Calling Manager\n",
      "Added - CountHours_BLOCK1_ZONE1 Program Calling Manager\n",
      "Added - SetAppLimits Program Calling Manager\n",
      "Added - ApplyCAT Program Calling Manager\n",
      "Added - SetAST Program Calling Manager\n",
      "Added - SetASTnoTol Program Calling Manager\n",
      "Added - CountHoursNoApp_BLOCK1_ZONE2 Program Calling Manager\n",
      "Added - SetGeoVarBLOCK1_ZONE2 Program Calling Manager\n",
      "Added - CountHoursNoApp_BLOCK1_ZONE1 Program Calling Manager\n",
      "Added - SetGeoVarBLOCK1_ZONE1 Program Calling Manager\n",
      "Added - SetInputData Program Calling Manager\n",
      "Added - SetVOFinputData Program Calling Manager\n",
      "Added - SetVST Program Calling Manager\n",
      "Added - ApplyAST_BLOCK1_ZONE2 Program Calling Manager\n",
      "Added - ApplyAST_BLOCK1_ZONE1 Program Calling Manager\n",
      "Added - SetMyVOF_Block1_Zone2_Wall_3_0_0_0_0_0_Win Program Calling Manager\n",
      "Added - SetWindowOperation_Block1_Zone2_Wall_3_0_0_0_0_0_Win Program Calling Manager\n",
      "Added - SetMyVOF_Block1_Zone2_Wall_4_0_0_0_0_0_Win Program Calling Manager\n",
      "Added - SetWindowOperation_Block1_Zone2_Wall_4_0_0_0_0_0_Win Program Calling Manager\n",
      "Added - SetMyVOF_Block1_Zone2_Wall_5_0_0_0_0_0_Win Program Calling Manager\n",
      "Added - SetWindowOperation_Block1_Zone2_Wall_5_0_0_0_0_0_Win Program Calling Manager\n",
      "Added - SetMyVOF_Block1_Zone1_Wall_2_0_0_0_0_0_Win Program Calling Manager\n",
      "Added - SetWindowOperation_Block1_Zone1_Wall_2_0_0_0_0_0_Win Program Calling Manager\n",
      "Added - SetMyVOF_Block1_Zone1_Wall_3_0_0_0_0_0_Win Program Calling Manager\n",
      "Added - SetWindowOperation_Block1_Zone1_Wall_3_0_0_0_0_0_Win Program Calling Manager\n",
      "Added - SetMyVOF_Block1_Zone1_Wall_5_0_0_0_0_0_Win Program Calling Manager\n",
      "Added - SetWindowOperation_Block1_Zone1_Wall_5_0_0_0_0_0_Win Program Calling Manager\n",
      "Added - Comfort Temperature Reporting FrequencyHourly Output:Variable data\n",
      "Added - Adaptive Cooling Setpoint Temperature Reporting FrequencyHourly Output:Variable data\n",
      "Added - Adaptive Heating Setpoint Temperature Reporting FrequencyHourly Output:Variable data\n",
      "Added - Adaptive Cooling Setpoint Temperature_No Tolerance Reporting FrequencyHourly Output:Variable data\n",
      "Added - Adaptive Heating Setpoint Temperature_No Tolerance Reporting FrequencyHourly Output:Variable data\n",
      "Added - Ventilation Setpoint Temperature Reporting FrequencyHourly Output:Variable data\n",
      "Added - Minimum Outdoor Temperature for ventilation Reporting FrequencyHourly Output:Variable data\n",
      "Added - Minimum Outdoor Temperature Difference for ventilation Reporting FrequencyHourly Output:Variable data\n",
      "Added - Maximum Outdoor Temperature Difference for ventilation Reporting FrequencyHourly Output:Variable data\n",
      "Added - Multiplier for Ventilation Opening Factor Reporting FrequencyHourly Output:Variable data\n",
      "Added - Comfortable Hours_No Applicability_BLOCK1_ZONE2 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Comfortable Hours_No Applicability_BLOCK1_ZONE1 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Comfortable Hours_Applicability_BLOCK1_ZONE2 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Comfortable Hours_Applicability_BLOCK1_ZONE1 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Discomfortable Applicable Hot Hours_BLOCK1_ZONE2 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Discomfortable Applicable Hot Hours_BLOCK1_ZONE1 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Discomfortable Applicable Cold Hours_BLOCK1_ZONE2 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Discomfortable Applicable Cold Hours_BLOCK1_ZONE1 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Discomfortable Non Applicable Hot Hours_BLOCK1_ZONE2 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Discomfortable Non Applicable Hot Hours_BLOCK1_ZONE1 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Discomfortable Non Applicable Cold Hours_BLOCK1_ZONE2 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Discomfortable Non Applicable Cold Hours_BLOCK1_ZONE1 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Zone Floor Area_BLOCK1_ZONE2 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Zone Floor Area_BLOCK1_ZONE1 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Zone Air Volume_BLOCK1_ZONE2 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Zone Air Volume_BLOCK1_ZONE1 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Ventilation Hours_BLOCK1_ZONE2 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Ventilation Hours_BLOCK1_ZONE1 Reporting FrequencyHourly Output:Variable data\n",
      "Added - Zone Operative Temperature Reporting FrequencyHourly Output:Variable data\n",
      "Added - Zone Thermal Comfort CEN 15251 Adaptive Model Running Average Outdoor Air Temperature Reporting FrequencyHourly Output:Variable data\n",
      "Added - Zone Thermal Comfort ASHRAE 55 Adaptive Model Running Average Outdoor Air Temperature Reporting FrequencyHourly Output:Variable data\n",
      "Added - Cooling Coil Total Cooling Rate Reporting FrequencyHourly Output:Variable data\n",
      "Added - Heating Coil Heating Rate Reporting FrequencyHourly Output:Variable data\n",
      "Added - Facility Total HVAC Electric Demand Power Reporting FrequencyHourly Output:Variable data\n",
      "Added - Facility Total HVAC Electricity Demand Rate Reporting FrequencyHourly Output:Variable data\n",
      "Added - AFN Surface Venting Window or Door Opening Factor Reporting FrequencyHourly Output:Variable data\n",
      "Added - AFN Zone Infiltration Air Change Rate Reporting FrequencyHourly Output:Variable data\n",
      "Added - AFN Zone Infiltration Volume Reporting FrequencyHourly Output:Variable data\n",
      "Added - AFN Zone Ventilation Air Change Rate Reporting FrequencyHourly Output:Variable data\n",
      "Added - AFN Zone Ventilation Volume Reporting FrequencyHourly Output:Variable data\n",
      "Added - Site Outdoor Air Drybulb Temperature Reporting FrequencyHourly Output:Variable data\n",
      "Added - Site Wind Speed Reporting FrequencyHourly Output:Variable data\n",
      "Added - Site Outdoor Air Relative Humidity Reporting FrequencyHourly Output:Variable data\n",
      "Added - AHST_Sch_BLOCK1_ZONE2 Reporting FrequencyHourly Output:Variable data\n",
      "Added - ACST_Sch_BLOCK1_ZONE2 Reporting FrequencyHourly Output:Variable data\n",
      "Added - AHST_Sch_BLOCK1_ZONE1 Reporting FrequencyHourly Output:Variable data\n",
      "Added - ACST_Sch_BLOCK1_ZONE1 Reporting FrequencyHourly Output:Variable data\n",
      "Added - VRF Heat Pump Cooling Electricity Energy Reporting FrequencyHourly Output:Variable data\n",
      "Added - VRF Heat Pump Heating Electricity Energy Reporting FrequencyHourly Output:Variable data\n",
      "Added - BLOCK1_ZONE2 VRF Indoor Unit DX Cooling Coil Reporting FrequencyHourly Output:Variable data\n",
      "Added - BLOCK1_ZONE2 VRF Indoor Unit DX Heating Coil Reporting FrequencyHourly Output:Variable data\n",
      "Added - BLOCK1_ZONE1 VRF Indoor Unit DX Cooling Coil Reporting FrequencyHourly Output:Variable data\n",
      "Added - BLOCK1_ZONE1 VRF Indoor Unit DX Heating Coil Reporting FrequencyHourly Output:Variable data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF has been saved\n",
      "Ending with file:\n",
      "TestModel\n",
      "\n",
      "=======================END OF GENERIC IDF FILE GENERATION PROCESS=======================\n",
      "\n",
      "The following IDFs will not work, and therefore these will be deleted:\n",
      "None\n",
      "\n",
      "=======================START OF OUTPUT IDF FILES GENERATION PROCESS=======================\n",
      "\n",
      "The list of output IDFs is going to be:\n",
      "TestModel[CS_INT ASHRAE55[CA_80[CM_0[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_INT ASHRAE55[CA_80[CM_0[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_INT ASHRAE55[CA_80[CM_3[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_INT ASHRAE55[CA_80[CM_3[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_JPN Rijal[CA_80[CM_0[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_JPN Rijal[CA_80[CM_0[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_JPN Rijal[CA_80[CM_3[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_JPN Rijal[CA_80[CM_3[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "And the total number of output IDFs is going to be 8\n",
      "Generating the following output IDF files:\n",
      "TestModel[CS_INT ASHRAE55[CA_80[CM_0[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_INT ASHRAE55[CA_80[CM_0[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_INT ASHRAE55[CA_80[CM_3[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_INT ASHRAE55[CA_80[CM_3[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_JPN Rijal[CA_80[CM_0[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_JPN Rijal[CA_80[CM_0[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_JPN Rijal[CA_80[CM_3[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_JPN Rijal[CA_80[CM_3[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "\n",
      "=======================END OF OUTPUT IDF FILES GENERATION PROCESS=======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from accim.sim import accis\n",
    "accis.addAccis(\n",
    "    ScriptType='vrf_mm',\n",
    "    SupplyAirTempInputMethod='temperature difference',\n",
    "    Output_keep_existing=False,\n",
    "    Output_type='standard',\n",
    "    Output_freqs=['hourly'],\n",
    "    EnergyPlus_version='23.1',\n",
    "    TempCtrl='temperature',\n",
    "    ComfStand=[2, 3],\n",
    "    CAT=[80],\n",
    "    ComfMod=[0, 3],\n",
    "    HVACmode=[1, 2],\n",
    "    VentCtrl=[0],\n",
    "    VSToffset=[0],\n",
    "    MinOToffset=[50],\n",
    "    MaxWindSpeed=[50],\n",
    "    ASTtol_steps=0.1,\n",
    "    ASTtol_start=0.1,\n",
    "    ASTtol_end_input=0.1,\n",
    "    confirmGen=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1557fa1e",
   "metadata": {},
   "source": [
    "So, now let's see the list of output IDFs we have generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58217779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestModel[CS_INT ASHRAE55[CA_80[CM_0[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_INT ASHRAE55[CA_80[CM_0[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_INT ASHRAE55[CA_80[CM_3[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_INT ASHRAE55[CA_80[CM_3[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_JPN Rijal[CA_80[CM_0[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_JPN Rijal[CA_80[CM_0[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_JPN Rijal[CA_80[CM_3[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_JPN Rijal[CA_80[CM_3[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n"
     ]
    }
   ],
   "source": [
    "output_idfs = [i for i in listdir() if i.endswith('.idf') and i not in input_idfs]\n",
    "print(*output_idfs, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d2541a",
   "metadata": {},
   "source": [
    "In this case, we have generated more IDFs than we need, so let's remove the others. We only want a single naturally ventilated IDF, to compare the indoor temperature with the mixed-mode IDF with adaptive setpoints. IDFs are NV when HVACmode takes the value 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab57bbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestModel[CS_INT ASHRAE55[CA_80[CM_0[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_INT ASHRAE55[CA_80[CM_0[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_JPN Rijal[CA_80[CM_0[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_JPN Rijal[CA_80[CM_3[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_JPN Rijal[CA_80[CM_3[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n"
     ]
    }
   ],
   "source": [
    "idfs_to_keep = [\n",
    "    'TestModel[CS_INT ASHRAE55[CA_80[CM_3[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf',\n",
    "    'TestModel[CS_INT ASHRAE55[CA_80[CM_3[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf',\n",
    "    'TestModel[CS_JPN Rijal[CA_80[CM_0[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf'\n",
    "]\n",
    "idfs_to_be_removed = [i for i in listdir() if i.endswith('.idf') and i not in idfs_to_keep and i not in input_idfs]\n",
    "print(*idfs_to_be_removed, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e69685a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove\n",
    "for i in idfs_to_be_removed:\n",
    "    remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b346defc",
   "metadata": {},
   "source": [
    "Let's see what IDFs we do finally have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df0fb88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestModel[CS_INT ASHRAE55[CA_80[CM_3[HM_1[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_INT ASHRAE55[CA_80[CM_3[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n",
      "TestModel[CS_JPN Rijal[CA_80[CM_0[HM_2[VC_0[VO_0.0[MT_50.0[MW_50.0[AT_0.1[NS_X.idf\n"
     ]
    }
   ],
   "source": [
    "output_idfs = [i for i in listdir() if i.endswith('.idf') and i not in input_idfs]\n",
    "print(*output_idfs, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519dc414",
   "metadata": {},
   "source": [
    "So, we're done with the IDFs. You can see these have been named based on the input data, separated by the character '['. Let's move to the EPWs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de92c008",
   "metadata": {},
   "source": [
    "## 2. EPW (using `rename_epw_files()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4e6d8",
   "metadata": {},
   "source": [
    "Let's see the EPWs we are going to use for the simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "624b8382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current_Naha_JA-hour.epw\n",
      "Current_Sapporo_JA-hour.epw\n",
      "rcp85_2100_Naha_JA-hour.epw\n",
      "rcp85_2100_Sapporo_JA-hour.epw\n"
     ]
    }
   ],
   "source": [
    "original_epws = [i for i in listdir() if i.endswith('.epw')]\n",
    "print(*original_epws, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8774f0",
   "metadata": {},
   "source": [
    "However, we don't want to run the simulations using that name. To ease the later data analysis, we are going to rename the EPW files following the pattern 'Country_City_RCPscenario-Year'. This way, data will be able to be grouped by country, city, RCP scenario and year. So let's rename them running the code in the cell below.\n",
    "\n",
    "First, accim will try to rename them based on the original name and the geolocation. If no match between those is found, accim will assign the string 'UNKNOWN' to the city. Then, accim will ask you if you want to edit some of the new names. If so, you'll need to enter the IDs:\n",
    "- If any of the city or subcountry names needs some amendment (if you are not happy with any of the available options, you can exclude it from renaming at the next stage), please enter the EPW IDs separated by space:**(hit enter)**\n",
    "\n",
    "Afterwards, you'll be asked to enter the new city name for each ID you previously entered (in this case, 0 1 2 3). So, \n",
    "- Regarding the file ID: 0 ... Please enter the amended city or subcountry, which must be unique: **Naha**\n",
    "- Regarding the file ID: 1 ... Please enter the amended city or subcountry, which must be unique: **Sapporo**\n",
    "- Regarding the file ID: 2 ... Please enter the amended city or subcountry, which must be unique: **Naha**\n",
    "- Regarding the file ID: 3 ... Please enter the amended city or subcountry, which must be unique: **Sapporo**\n",
    "\n",
    "Then, accim will let you know the old names, and the new named after amendments. Next, accim will ask you if you want to exclude some EPW from renaming. In this case, we're just going to hit enter to continue because we don't want to exclude any:\n",
    "- If you want to exclude some EPWs from renaming, please enter the new names separated by space, otherwise, hit enter to continue:\n",
    "\n",
    "Finally, accim will ask for confirmation to proceed with the renaming:\n",
    "Do you want to rename the file or files? [y/n]:**y**\n",
    "\n",
    "At this point, accim will make a copy of the EPWs and rename them. Afterwards, we would be asked if we want to delete the older EPWs. In this case, we won't because the deletion has been already set to False in the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c9fd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since no match has been found between RCP scenario Year and EPW file name, Present year has been assigned to the following EPW files:\n",
      "Current_Naha_JA-hour.epw\n",
      "Current_Sapporo_JA-hour.epw\n",
      "The geolocation process has taken: 1.71 seconds (0.43 s/EPW)\n",
      "\n",
      "The previous and new names of the EPW files and their unique IDs are:\n",
      "ID: 0 / Current_Naha_JA-hour / Japan_UNKNOWN_Present\n",
      "ID: 1 / Current_Sapporo_JA-hour / Japan_UNKNOWN_Present\n",
      "ID: 2 / rcp85_2100_Naha_JA-hour / Japan_UNKNOWN_RCP85-2100\n",
      "ID: 3 / rcp85_2100_Sapporo_JA-hour / Japan_UNKNOWN_RCP85-2100\n",
      "\n",
      "Duplicates have been found in the renamed EPW files, therefore these need to be amended in the next stage:\n",
      "['Japan_UNKNOWN_RCP85-2100', 'Japan_UNKNOWN_Present']\n",
      "\n",
      "\"UNKNOWN\" city or subcountry have been found in the renamed EPW files, therefore these need to be amended in the next stage.\n"
     ]
    }
   ],
   "source": [
    "from accim.data.data_preprocessing import rename_epw_files\n",
    "rename_epw_files(\n",
    "    rename_dict={\n",
    "        'Naha': 'Naha',\n",
    "        'Sapporo': 'Sapporo'\n",
    "    },\n",
    "    confirm_deletion=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f247dd9",
   "metadata": {},
   "source": [
    "Now, let's see what EPWs we do have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49abc6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japan_Naha_Present.epw\n",
      "Japan_Naha_RCP85-2100.epw\n",
      "Japan_Sapporo_Present.epw\n",
      "Japan_Sapporo_RCP85-2100.epw\n"
     ]
    }
   ],
   "source": [
    "all_epws = [i for i in listdir() if i.endswith('.epw')]\n",
    "print(*all_epws, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a4f14",
   "metadata": {},
   "source": [
    "We can see the new EPWs are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5ba5c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_epws = [i for i in listdir() if i.endswith('.epw') if i not in original_epws]\n",
    "print(*new_epws, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88b38e",
   "metadata": {},
   "source": [
    "EPWs are correctly renamed, so now let's move the old EPWs to a different folder to save them as a backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c4f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for i in original_epws:\n",
    "    shutil.move(i, f'backup/{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc6f12",
   "metadata": {},
   "source": [
    "Now, we can move to the next stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe727e8",
   "metadata": {},
   "source": [
    "## 3. Running the simulation (using `runEp()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16603780",
   "metadata": {},
   "source": [
    "At this point, we have prepared the IDF(s) we are going to simulate, which are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c534e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*output_idfs, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfc9e5b",
   "metadata": {},
   "source": [
    "as well as the locations where we are going to run those simulations, whose EPWs are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8946029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*new_epws, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc9fcfb",
   "metadata": {},
   "source": [
    "So, we are going to simulate all IDF(s) with all EPW(s). When we run later the simulations using accim, the output files (i.e. the CSVs) will be named following the pattern **'idf[epw'**, where the character '[' is used as a separator for later data analysis, so that CSV rows can be grouped by EPW location. You may have noticed the same character is used as a separator in the IDF name, in order to group the CSV rows depending on the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac424a70",
   "metadata": {},
   "source": [
    "To run the simulations, 2 methods can be used:\n",
    "- the shorter, in which the following 2 lines of code needs to be run:\n",
    "    ```\n",
    "    from accim.run import run\n",
    "    run.runEp()\n",
    "    ```\n",
    "   After this, you'll be asked to enter the EnergyPlus version (which should coincide with the IDF EnergyPlus version):\n",
    "    - Please enter the desired EnergyPlus version: **23.1**\n",
    "    \n",
    "   Then, you will need to say if you want to run only output IDFs of accim, or otherwise all existing IDFs in the folder:\n",
    "    - Do you want to run only ACCIM output IDFs? [y or n]: **y**\n",
    "    \n",
    "   Next, accim will tell you the IDF(s) and EPW(s) it's going to use for the simulations, and finally all the simulations it's going to run based on the name pattern 'idf[epw'.\n",
    "   Finally, it will ask for confirmation to proceed with the simulation:\n",
    "    - Do you still want to proceed? [y or n]:**y**\n",
    "- the longer method, in which the parameters are specified when calling the function. We'll use the longer method, so let's run the cell below. Since there are a few simulations, it might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17de90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accim.run import run\n",
    "run.runEp(\n",
    "    runOnlyAccim=True, #only runs output IDFs, that is, IDFs with \"[\" in its name\n",
    "    confirmRun=True, #to skip confirmation\n",
    "    num_CPUs=4, #to specify the number of CPUs to be used\n",
    "    EnergyPlus_version='23.1', #to specify the EnergyPlus version of the IDF, and the version of EnergyPlus you are going to run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b89d15a",
   "metadata": {},
   "source": [
    "So simulations are done. Let's see the CSV data we have now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692742de",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = [i for i in listdir() if i.endswith('.csv') and 'Zsz.csv' not in i and 'Table.csv' not in i]\n",
    "print(*csvs, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43224aa7",
   "metadata": {},
   "source": [
    "Now, we can move to the last stage, in which data will be analysed and visualized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b781bd",
   "metadata": {},
   "source": [
    "## 4. Analysing and visualising the data (using `Table()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6201e8b4",
   "metadata": {},
   "source": [
    "In order to analyse and visualize the data, we need to make a pandas DataFrame out of the CSVs. We will do this by using the `Table()` method. To use this method, a minimum knowledge and experience with Python programming is needed, so if this is not your case, you may struggle to make it work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82037ddf",
   "metadata": {},
   "source": [
    "Let's create an hourly dataframe, since firstly we are going to compare indoor temperature with and without adaptive setpoint temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d8a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accim.data.data_postprocessing import Table\n",
    "dataset_hourly = Table(\n",
    "    #datasets=list #Since we are not specifying any list, it will use all available CSVs in the folder\n",
    "    source_frequency='hourly', # This lets accim know which is the frequency of the input CSVs. Input CSVs with multiple frequencies are also allowed. It can be 'hourly', 'daily', 'monthly' and 'runperiod'. It can also be 'timestep' but might generate errors.\n",
    "    frequency='hourly', # If 'daily', accim will aggregate the rows in days. It can be 'hourly', 'daily', 'monthly' and 'runperiod'. It can also be 'timestep' but might generate errors.\n",
    "    frequency_agg_func='sum', #this makes the sum or average when aggregating in days, months or runperiod; since the original CSV frequency is in hour, it won't make any aeffect\n",
    "    standard_outputs=True, \n",
    "    level=['building'], # A list containing the strings 'block' and/or 'building'. For instance, if ['block', 'building'], accim will generate new columns to sum up or average in blocks and building level.\n",
    "    level_agg_func=['sum', 'mean'], # A list containing the strings 'sum' and/or 'mean'. For instance, if ['sum', 'mean'], accim will generate the new columns explained in the level argument by summing and averaging.\n",
    "    level_excluded_zones=[],\n",
    "    split_epw_names=True, #to split EPW names based on the pattern Country_City_RCPscenario-Year\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af556a87",
   "metadata": {},
   "source": [
    "So let's take a look at the DataFrame instance 'df' we have stored within Table instance 'dataset_hourly'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ecf060",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hourly.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16cd655",
   "metadata": {},
   "source": [
    "And the shape is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604078a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hourly.df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4581f539",
   "metadata": {},
   "source": [
    "Let's filter the columns we are going to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e04077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hourly.format_table(\n",
    "    type_of_table='custom', # Used to choose some predefined tables. It can be 'energy demand', 'comfort hours', 'temperature', 'all' or 'custom'\n",
    "    custom_cols=[ #if type_of_table is 'custom', custom_cols is used to filter the desired columns to keep\n",
    "        'Adaptive Cooling Setpoint Temperature_No Tolerance (°C)',\n",
    "        'Adaptive Heating Setpoint Temperature_No Tolerance (°C)',\n",
    "        'Building_Total_Zone Operative Temperature (°C) (mean)',\n",
    "        'BLOCK1:ZONE2_ASHRAE 55 Running mean outdoor temperature (°C)',\n",
    "        'Building_Total_Cooling Energy Demand (kWh/m2) (summed)',\n",
    "        'Building_Total_Heating Energy Demand (kWh/m2) (summed)',\n",
    "        'Building_Total_AFN Zone Infiltration Air Change Rate (ach) (summed)'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dff889",
   "metadata": {},
   "source": [
    "Again, let's take a look at the filtered df and the new shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28438fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hourly.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d6da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hourly.df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292627c2",
   "metadata": {},
   "source": [
    "### 4.1 Visualizing the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63478dca",
   "metadata": {},
   "source": [
    "At this point, the user might have a vague idea of what table can be done with the available data, especially if there is a large number of categorical variables. In order to get a clearer idea of this, the user can call the method named gather_vars_query. It only takes one argument, named vars_to_gather, which should be a list of the variables to be combined.\n",
    "\n",
    "In this case, when IDFs with adaptive setpoint were generated, the arguments where more than one than one value were requested were ComfStand, ComfMod and HVACmode (ComfStand=[2, 3], ComfMod=[0, 3], HVACmode=[1, 2]). Therefore, these are all the categorical variables that change regarding the IDFs and the possibilities that might be interesting to study, and therefore the variables that have been entered in vars_to_gather.\n",
    "\n",
    "Then, after calling gather_vars_query, accim prints on screen the categorical variables that contains more than one different value (i.e. ComfMod, since values are “CM_0” and “CM_3”), and the different combinations based on the combined variables, joined by character “[“:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hourly.gather_vars_query(['ComfStand', 'ComfMod', 'HVACmode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7951ffa",
   "metadata": {},
   "source": [
    "And now, let's generate the figure data (a list of lists and dictionaries with all information to be plotted) with `generate_fig_data()` and afterwards, let's plot the figure with `scatter_plot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d385ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_hourly.scatter_plot(\n",
    "    vars_to_gather_rows=['EPW'], # variables to gather in rows of subplots\n",
    "    vars_to_gather_cols=['ComfStand', 'ComfMod', 'HVACmode'],# variables to gather in columns of subplots; all categorical columns which have more than 1 different value across the rows, must be specified in this argument, otherwise you'll get an error.\n",
    "    detailed_cols=['CS_INT ASHRAE55[CM_3[HM_1', 'CS_INT ASHRAE55[CM_3[HM_2'], # a list of the specific combinations of arguments to be plotted joined by [\n",
    "    data_on_x_axis='BLOCK1:ZONE2_ASHRAE 55 Running mean outdoor temperature (°C)', #column name (string) for the data on x axis\n",
    "    data_on_y_main_axis=[ #list which includes the name of the axis on the first place, and then in the second place, a list which includes the column names you want to plot\n",
    "        [\n",
    "            'Indoor Operative Temperature (°C)',\n",
    "            [\n",
    "                'Adaptive Cooling Setpoint Temperature_No Tolerance (°C)',\n",
    "                'Adaptive Heating Setpoint Temperature_No Tolerance (°C)',\n",
    "                'Building_Total_Zone Operative Temperature (°C) (mean)',\n",
    "            ]\n",
    "        ],\n",
    "    ],\n",
    "    colorlist_y_main_axis=[\n",
    "        [\n",
    "            'Indoor Operative Temperature (°C)',\n",
    "            [\n",
    "                'b',\n",
    "                'r',\n",
    "                'g',\n",
    "            ]\n",
    "        ],\n",
    "    ],\n",
    "    supxlabel='Running Mean Outdoor Temperature (°C)', # data label on x axis\n",
    "    figname=f'Scatterplot_NV_vs_MM',\n",
    "    figsize=6,\n",
    "    ratio_height_to_width=0.33,\n",
    "    confirm_graph=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339ad6d2",
   "metadata": {},
   "source": [
    "In this figure, you can see on the left column the simulations with free-running (or naturally ventilated) mode, while on the right, the same simulations using mixed-mode with adaptive setpoint temperatures, which introduce all hourly indoor temperatures within the adaptive thermal comfort limits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358ac545",
   "metadata": {},
   "source": [
    "Next, let's compare the indoor temperatures of ASHRAE 55 and the static setpoints for Japan, and in this case, we're also going to plot the hourly energy demand on the main y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd0180",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hourly.scatter_plot(\n",
    "    vars_to_gather_cols=['ComfStand', 'ComfMod', 'HVACmode'], # variables to gather in rows of subplots\n",
    "    vars_to_gather_rows=['EPW'],# variables to gather in columns of subplots\n",
    "    detailed_cols=['CS_JPN Rijal[CM_0[HM_2', 'CS_INT ASHRAE55[CM_3[HM_2'], #we only want to see those combinations\n",
    "    data_on_x_axis='BLOCK1:ZONE2_ASHRAE 55 Running mean outdoor temperature (°C)', #column name (string) for the data on x axis\n",
    "    data_on_y_sec_axis=[ #list which includes the name of the axis on the first place, and then in the second place, a list which includes the column names you want to plot\n",
    "        [\n",
    "            'Air renovation (ach)',\n",
    "            [\n",
    "                'Building_Total_AFN Zone Infiltration Air Change Rate (ach) (summed)'\n",
    "            ]\n",
    "        ],\n",
    "        [\n",
    "            'Operative Temperature (°C)',\n",
    "            [\n",
    "                'Adaptive Cooling Setpoint Temperature_No Tolerance (°C)',\n",
    "                'Adaptive Heating Setpoint Temperature_No Tolerance (°C)',\n",
    "                'Building_Total_Zone Operative Temperature (°C) (mean)',\n",
    "            ]\n",
    "        ],\n",
    "    ],\n",
    "    data_on_y_main_axis=[ # similarly to above, a list including the name of the secondary y-axis and the column names you want to plot in it\n",
    "        [\n",
    "            'Energy (kWh/m2)',\n",
    "            [\n",
    "                'Building_Total_Cooling Energy Demand (kWh/m2) (summed)',\n",
    "                'Building_Total_Heating Energy Demand (kWh/m2) (summed)',\n",
    "            ]\n",
    "        ],\n",
    "\n",
    "    ],\n",
    "    colorlist_y_sec_axis=[\n",
    "        [\n",
    "            'Air renovation (ach)',\n",
    "            [\n",
    "                'yellow'\n",
    "            ]\n",
    "        ],\n",
    "        [\n",
    "            'Operative Temperature (°C)',\n",
    "            [\n",
    "                'b',\n",
    "                'r',\n",
    "                'g',\n",
    "            ]\n",
    "        ],\n",
    "    ],\n",
    "    colorlist_y_main_axis=[\n",
    "        [\n",
    "            'Energy (kWh/m2)',\n",
    "            [\n",
    "                'cyan',\n",
    "                'orange',\n",
    "            ]\n",
    "        ],\n",
    "    ],\n",
    "    supxlabel='Running Mean Outdoor Temperature (°C)', # data label on x axis\n",
    "    figname=f'scatterplot_JPN_stat_ASH_adap_JPN_adap',\n",
    "    figsize=6,\n",
    "    ratio_height_to_width=0.33,\n",
    "    confirm_graph=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3439256f",
   "metadata": {},
   "source": [
    "### 4.2 Analysing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec8ec84",
   "metadata": {},
   "source": [
    "Now, let's see how many comfort hours were considering the NV mode, and afterwards the MM considering ASHRAE 55, as well as the impact on energy demand. Since we want to see the runperiod totals, we will need to make a new instance of Table(), asking for runperiod frequency this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accim.data.data_postprocessing import Table\n",
    "dataset_runperiod = Table(\n",
    "    #datasets=list #Since we are not specifying any list, it will use all available CSVs in the folder\n",
    "    source_frequency='hourly', # This lets accim know which is the frequency of the input CSVs. Input CSVs with multiple frequencies are also allowed. It can be 'hourly', 'daily', 'monthly' and 'runperiod'. It can also be 'timestep' but might generate errors.\n",
    "    frequency='runperiod', # If 'daily', accim will aggregate the rows in days. It can be 'hourly', 'daily', 'monthly' and 'runperiod'. It can also be 'timestep' but might generate errors.\n",
    "    frequency_agg_func='sum', #this makes the sum or average when aggregating in days, months or runperiod; since the original CSV frequency is in hour, it won't make any aeffect\n",
    "    standard_outputs=True, \n",
    "    level=['building'], # A list containing the strings 'block' and/or 'building'. For instance, if ['block', 'building'], accim will generate new columns to sum up or average in blocks and building level.\n",
    "    level_agg_func=['sum', 'mean'], # A list containing the strings 'sum' and/or 'mean'. For instance, if ['sum', 'mean'], accim will generate the new columns explained in the level argument by summing and averaging.\n",
    "    level_excluded_zones=[],\n",
    "    split_epw_names=True, #to split EPW names based on the pattern Country_City_RCPscenario-Year\n",
    ")\n",
    "\n",
    "dataset_runperiod.format_table(\n",
    "    type_of_table='custom',\n",
    "    custom_cols=[\n",
    "        'Building_Total_Comfortable Hours_No Applicability (h) (mean)',\n",
    "        'Building_Total_Total Energy Demand (kWh/m2) (summed)'\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset_runperiod.wrangled_table(\n",
    "    reshaping='unstack',\n",
    "    vars_to_gather=['ComfStand', 'ComfMod', 'HVACmode'],\n",
    "    baseline='CS_INT ASHRAE55[CM_3[HM_2',\n",
    "    comparison_mode=['baseline compared to others'],\n",
    "    comparison_cols=['absolute'],\n",
    "    rename_dict={\n",
    "        'CS_INT ASHRAE55[CM_3[HM_1': 'ASHRAE55_NV',\n",
    "        'CS_INT ASHRAE55[CM_3[HM_2': 'ASHRAE55_MM',\n",
    "        'CS_JPN Rijal[CM_0[HM_2': 'JPN_Stat_MM'\n",
    "    }\n",
    ")\n",
    "\n",
    "dataset_runperiod.wrangled_df_unstacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a41cfe5",
   "metadata": {},
   "source": [
    "The table above shows us the comfort hours in NV (CS_INT ASHRAE55[CM_3[HM_1) mode ranges between 5111.58 and 6940.58 hours, while the same comfort model in mixed-mode with adaptive setpoints (CS_INT ASHRAE55[CM_3[HM_2) ranges between 8598.15 and 8758.85. Since there is no HVAC system in NV mode, the energy consumption is 0. With adaptive setpoints, the hvac energy consumption ranges between 265.82 and 419.02 (kWh/m2·year)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4501f",
   "metadata": {},
   "source": [
    "Now, we could finally export this table to Excel format for later style edition. Since the reshaping argument we used in the `wrangled_table()` method was 'unstack', the dataframe we are looking for to be exported is `dataset_runperiod.wrangled_df_unstacked`. If we used the 'pivot' argument, the dataframe would have been `dataset_runperiod.wrangled_df_pivoted`. So let's export it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bbc43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_runperiod.wrangled_df_unstacked.to_excel('df_unstacked.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb1efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('df_unstacked.xlsx', index_col=[0, 1, 2], header=[0, 1])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bc70a2",
   "metadata": {},
   "source": [
    "Finally, so that we can run this jupyter notebook again, let's leave everything as it was at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb035b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in original_epws:\n",
    "    shutil.move(f'backup/{i}', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6137656",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_delete = [i for i in listdir() if i not in input_files]\n",
    "print(*files_to_delete, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d79466",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in files_to_delete:\n",
    "    remove(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
